{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:46.908848Z","iopub.status.busy":"2022-04-02T23:38:46.908616Z","iopub.status.idle":"2022-04-02T23:38:46.915579Z","shell.execute_reply":"2022-04-02T23:38:46.914821Z","shell.execute_reply.started":"2022-04-02T23:38:46.908819Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","import torchaudio\n","import matplotlib.pyplot as plt\n","import random\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from efficientnet_pytorch import EfficientNet\n","import torch.nn as nn\n","import time\n","import copy\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["<h1> 1. Preprocessing </h1>"]},{"cell_type":"markdown","metadata":{},"source":["<h3>1.1 Load the training data</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:46.917815Z","iopub.status.busy":"2022-04-02T23:38:46.917138Z","iopub.status.idle":"2022-04-02T23:38:46.925715Z","shell.execute_reply":"2022-04-02T23:38:46.924904Z","shell.execute_reply.started":"2022-04-02T23:38:46.917777Z"},"trusted":true},"outputs":[],"source":["DIR_PATH = '../input/birdsong-recognition'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:46.929089Z","iopub.status.busy":"2022-04-02T23:38:46.928415Z","iopub.status.idle":"2022-04-02T23:38:46.937706Z","shell.execute_reply":"2022-04-02T23:38:46.93646Z","shell.execute_reply.started":"2022-04-02T23:38:46.929051Z"},"trusted":true},"outputs":[],"source":["def get_dataset_path(ebird_code, relative_path):\n","    path = '../input/birdsong-resampled-train-audio-'\n","    if ('a' <= ebird_code[0] <= 'b'):\n","        path += '00'\n","    elif ('c' <= ebird_code[0] <= 'f'):\n","        path += '01'\n","    elif ('g' <= ebird_code[0] <= 'm'):\n","        path += '02'\n","    elif ('n' <= ebird_code[0] <= 'r'):\n","        path += '03'\n","    elif ('s' <= ebird_code[0] <= 'y'):\n","        path += '04'\n","    return path + relative_path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:46.939903Z","iopub.status.busy":"2022-04-02T23:38:46.939269Z","iopub.status.idle":"2022-04-02T23:38:47.235777Z","shell.execute_reply":"2022-04-02T23:38:47.23498Z","shell.execute_reply.started":"2022-04-02T23:38:46.939801Z"},"trusted":true},"outputs":[],"source":["metadata = pd.read_csv(f'{DIR_PATH}/train.csv')\n","metadata = metadata.query('rating >= 4.5') # Use only high quality recordings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.237516Z","iopub.status.busy":"2022-04-02T23:38:47.237246Z","iopub.status.idle":"2022-04-02T23:38:47.263138Z","shell.execute_reply":"2022-04-02T23:38:47.262428Z","shell.execute_reply.started":"2022-04-02T23:38:47.237472Z"},"trusted":true},"outputs":[],"source":["birds_count = {}\n","for bird_species, count in zip(metadata.ebird_code.unique(), metadata.groupby(\"ebird_code\")[\"ebird_code\"].count().values):\n","    birds_count[bird_species] = count\n","\n","birds = sorted(birds_count.items(), key=lambda kv: kv[1], reverse=True)[:20] # Select top 20 most represented birds\n","birds = [key for key, value in birds]\n","metadata = metadata.query('ebird_code in @birds')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.265292Z","iopub.status.busy":"2022-04-02T23:38:47.264937Z","iopub.status.idle":"2022-04-02T23:38:47.270357Z","shell.execute_reply":"2022-04-02T23:38:47.26941Z","shell.execute_reply.started":"2022-04-02T23:38:47.265255Z"},"trusted":true},"outputs":[],"source":["print(birds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.272831Z","iopub.status.busy":"2022-04-02T23:38:47.272125Z","iopub.status.idle":"2022-04-02T23:38:47.332562Z","shell.execute_reply":"2022-04-02T23:38:47.331787Z","shell.execute_reply.started":"2022-04-02T23:38:47.272761Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame()\n","df['path'] = \"/\" + metadata['ebird_code'].astype(str) + \"/\" + metadata['filename'].str.replace('mp3', 'wav')\n","df['class'] = metadata['ebird_code']\n","df['path'] = df.apply(lambda row: get_dataset_path(row['class'], row['path']), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.334267Z","iopub.status.busy":"2022-04-02T23:38:47.333927Z","iopub.status.idle":"2022-04-02T23:38:47.339424Z","shell.execute_reply":"2022-04-02T23:38:47.338364Z","shell.execute_reply.started":"2022-04-02T23:38:47.33423Z"},"trusted":true},"outputs":[],"source":["df = df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.344209Z","iopub.status.busy":"2022-04-02T23:38:47.343911Z","iopub.status.idle":"2022-04-02T23:38:47.351828Z","shell.execute_reply":"2022-04-02T23:38:47.350994Z","shell.execute_reply.started":"2022-04-02T23:38:47.344175Z"},"trusted":true},"outputs":[],"source":["le = LabelEncoder()\n","le.fit(df[\"class\"])\n","df[\"class\"] = le.transform(df[\"class\"]) # Encode class names as integers"]},{"cell_type":"markdown","metadata":{},"source":["<h3>1.2 Convert audio to mel spectrograms</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.353745Z","iopub.status.busy":"2022-04-02T23:38:47.353458Z","iopub.status.idle":"2022-04-02T23:38:47.37237Z","shell.execute_reply":"2022-04-02T23:38:47.371492Z","shell.execute_reply.started":"2022-04-02T23:38:47.353712Z"},"trusted":true},"outputs":[],"source":["def read(file_path):\n","    waveform, sample_rate = torchaudio.load(file_path)\n","    return waveform, sample_rate\n","\n","def rechannel(audio):\n","    waveform, sample_rate = audio\n","    if waveform.shape[0] == 1:\n","        return waveform, sample_rate\n","    waveform = waveform[:1, :]\n","    return waveform, sample_rate\n","\n","def resize(audio, seconds=10):\n","    waveform, sample_rate = audio\n","    length = waveform.shape[1]\n","    max_length = sample_rate * seconds\n","    \n","    if length > max_length:\n","        trim_start = random.randint(0, length - max_length)\n","        trim_end = trim_start + max_length\n","        \n","        waveform  = waveform[:,trim_start:trim_end]\n","    \n","    elif length < max_length:\n","        pad_start_lenght = (max_length - length) // 2\n","        pad_end_length = max_length - length - pad_start_lenght\n","        \n","        pad_start = torch.zeros((1, pad_start_lenght))\n","        pad_end = torch.zeros((1, pad_end_length))\n","        \n","        waveform = torch.cat((pad_start, waveform, pad_end), 1)\n","    \n","    return waveform, sample_rate\n","\n","def high_pass(audio, f_min=1400):\n","    waveform, sample_rate = audio\n","    \n","    waveform = torchaudio.functional.highpass_biquad(waveform, sample_rate, f_min)\n","    \n","    return waveform, sample_rate\n","\n","def preprocess(file_path):\n","    return high_pass(resize(rechannel(read(file_path))))\n","\n","def get_spectrogram(file_path, n_mels=128, n_fft=1024, hop_len=1024, top_db=80):\n","    audio, sr = preprocess(file_path)\n","    spec = torchaudio.transforms.MelSpectrogram(sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_len)(audio)\n","    spec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n","    \n","    return spec"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.374625Z","iopub.status.busy":"2022-04-02T23:38:47.374048Z","iopub.status.idle":"2022-04-02T23:38:47.629746Z","shell.execute_reply":"2022-04-02T23:38:47.628874Z","shell.execute_reply.started":"2022-04-02T23:38:47.374587Z"},"trusted":true},"outputs":[],"source":["spec = get_spectrogram(df['path'][0])\n","ax = plt.imshow(spec.squeeze().numpy())"]},{"cell_type":"markdown","metadata":{},"source":["<h1> 2. Training </h1>"]},{"cell_type":"markdown","metadata":{},"source":["<h3>2.1 Define datasets</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.639015Z","iopub.status.busy":"2022-04-02T23:38:47.638288Z","iopub.status.idle":"2022-04-02T23:38:47.648204Z","shell.execute_reply":"2022-04-02T23:38:47.647151Z","shell.execute_reply.started":"2022-04-02T23:38:47.63897Z"},"trusted":true},"outputs":[],"source":["class BirdsongDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        path = self.df.iloc[index, 0]\n","        label = self.df.iloc[index, 1]\n","        spec = get_spectrogram(path)\n","        if (self.transform):\n","            spec = self.transform(spec)\n","        spec = spec.expand(3, -1, -1) # Expand to 3 channel (RGB) image\n","        return spec, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.650229Z","iopub.status.busy":"2022-04-02T23:38:47.64982Z","iopub.status.idle":"2022-04-02T23:38:47.657308Z","shell.execute_reply":"2022-04-02T23:38:47.656352Z","shell.execute_reply.started":"2022-04-02T23:38:47.650194Z"},"trusted":true},"outputs":[],"source":["dataset = BirdsongDataset(df)"]},{"cell_type":"markdown","metadata":{},"source":["<h3>2.2 Split dataset into training, validation, and test sets</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.659423Z","iopub.status.busy":"2022-04-02T23:38:47.659038Z","iopub.status.idle":"2022-04-02T23:38:47.671051Z","shell.execute_reply":"2022-04-02T23:38:47.670174Z","shell.execute_reply.started":"2022-04-02T23:38:47.659385Z"},"trusted":true},"outputs":[],"source":["num_train = round(0.8 * len(dataset)) # 80% train set\n","num_test = len(dataset) - num_train\n","\n","train_ds, test_ds = random_split(dataset, [num_train, num_test])\n","\n","num_val = len(test_ds) // 2 # 10% validation set\n","num_test = len(test_ds) - num_val # 10% test set\n","\n","val_ds, test_ds = random_split(test_ds, [num_val, num_test])\n","\n","image_datasets = {\n","    'train': train_ds,\n","    'val': val_ds,\n","    'test': test_ds\n","}\n","\n","dataloaders = {\n","    'train': DataLoader(train_ds, batch_size=16, shuffle=True),\n","    'val': DataLoader(val_ds, batch_size=16, shuffle=False),\n","    'test': DataLoader(test_ds, batch_size=16, shuffle=False)\n","}\n","\n","dataset_sizes = {\n","    'train': len(train_ds),\n","    'val': len(val_ds),\n","    'test': len(test_ds)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["<h3>2.3 Load pretrained model</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:47.673158Z","iopub.status.busy":"2022-04-02T23:38:47.672729Z","iopub.status.idle":"2022-04-02T23:38:48.770607Z","shell.execute_reply":"2022-04-02T23:38:48.76973Z","shell.execute_reply.started":"2022-04-02T23:38:47.673123Z"},"trusted":true},"outputs":[],"source":["model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=df['class'].max() + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:48.772824Z","iopub.status.busy":"2022-04-02T23:38:48.772109Z","iopub.status.idle":"2022-04-02T23:38:48.893409Z","shell.execute_reply":"2022-04-02T23:38:48.892704Z","shell.execute_reply.started":"2022-04-02T23:38:48.77276Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["<h3>2.4 Train the model</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:48.895048Z","iopub.status.busy":"2022-04-02T23:38:48.894783Z","iopub.status.idle":"2022-04-02T23:38:48.90509Z","shell.execute_reply":"2022-04-02T23:38:48.904246Z","shell.execute_reply.started":"2022-04-02T23:38:48.895013Z"},"trusted":true},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer_ft = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:48.906944Z","iopub.status.busy":"2022-04-02T23:38:48.906676Z","iopub.status.idle":"2022-04-02T23:38:48.923142Z","shell.execute_reply":"2022-04-02T23:38:48.922104Z","shell.execute_reply.started":"2022-04-02T23:38:48.906897Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluation mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # Zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # Forward\n","                # Track history only if training\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # Backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # Stats\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            \n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Accuracy: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # Save best weights\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                torch.save(best_model_wts, f'state-{epoch}-{time.time()}.pt')\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best validation accuracy: {:4f}'.format(best_acc))\n","\n","    # Load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-02T23:38:48.924992Z","iopub.status.busy":"2022-04-02T23:38:48.924694Z","iopub.status.idle":"2022-04-02T23:51:02.663527Z","shell.execute_reply":"2022-04-02T23:51:02.662186Z","shell.execute_reply.started":"2022-04-02T23:38:48.924952Z"},"trusted":true},"outputs":[],"source":["model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=75)"]},{"cell_type":"markdown","metadata":{},"source":["<h1> 3. Testing </h1>"]},{"cell_type":"markdown","metadata":{},"source":["<h3>3.1 Evaluate model on test set</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-02T23:51:02.664809Z","iopub.status.idle":"2022-04-02T23:51:02.665207Z","shell.execute_reply":"2022-04-02T23:51:02.665017Z","shell.execute_reply.started":"2022-04-02T23:51:02.664995Z"},"trusted":true},"outputs":[],"source":["def predict():\n","    model.eval()\n","    y_pred = None\n","    y_true = None\n","    for i, [images, labels] in enumerate(dataloaders['test']):\n","        with torch.no_grad():\n","            images = images.to(device)\n","            outputs = model(images)\n","            _, preds = torch.max(outputs, 1)\n","            if (y_pred is None):\n","                y_pred = preds\n","            else:\n","                y_pred = torch.cat((y_pred, preds))\n","            if (y_true is None):\n","                y_true = labels\n","            else:\n","                y_true = torch.cat((y_true, labels))\n","    return y_pred.cpu().numpy(), y_true.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-02T23:51:02.666354Z","iopub.status.idle":"2022-04-02T23:51:02.66687Z","shell.execute_reply":"2022-04-02T23:51:02.666655Z","shell.execute_reply.started":"2022-04-02T23:51:02.66663Z"},"trusted":true},"outputs":[],"source":["y_pred, y_true = predict()"]},{"cell_type":"markdown","metadata":{},"source":["<h3>3.2 Generate confusion matrix and classification report</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-02T23:51:02.668239Z","iopub.status.idle":"2022-04-02T23:51:02.669Z","shell.execute_reply":"2022-04-02T23:51:02.668769Z","shell.execute_reply.started":"2022-04-02T23:51:02.668745Z"},"trusted":true},"outputs":[],"source":["conf_matrix = confusion_matrix(y_true, y_pred)\n","print(conf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-02T23:51:02.670121Z","iopub.status.idle":"2022-04-02T23:51:02.670865Z","shell.execute_reply":"2022-04-02T23:51:02.670653Z","shell.execute_reply.started":"2022-04-02T23:51:02.670629Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(11, 9))\n","ax = sns.heatmap(conf_matrix, annot=True)\n","ax.xaxis.set_ticklabels(birds)\n","ax.yaxis.set_ticklabels(birds)\n","plt.xticks(rotation=90)\n","plt.yticks(rotation=0)\n","plt.savefig('confusion_matrix.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-02T23:51:02.671899Z","iopub.status.idle":"2022-04-02T23:51:02.672652Z","shell.execute_reply":"2022-04-02T23:51:02.672425Z","shell.execute_reply.started":"2022-04-02T23:51:02.672401Z"},"trusted":true},"outputs":[],"source":["print(classification_report(y_true, y_pred, target_names=birds))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
